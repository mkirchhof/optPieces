indPiece <- indPiece + 1
}
nPieces <- indPiece - 1
# compute summary information
maxPos <- sapply(data, function(dat) max(dat[, 2]))
minPos <- sapply(data, function(dat) min(dat[, 2]))
results <- list()
results[["summary"]] <- c("length" = l,
"nPieces" = nPieces,
"goodMaterial" = l * nPieces,
"allMaterial" = max(maxPos - minPos),
"badMaterial" = max(maxPos - minPos) - l * nPieces,
"badMaterialPercent" = (1 - (l * nPieces / max(maxPos - minPos))) * 100)
results[["piecePositions"]] <- piecePositions
if(keepDetails) results[["pieceData"]] <- pieceDetails
results[["pieceOutliers"]] <-	pieceOutliers
results[["data"]] <- data
results[["params"]] <- params
class(results) <- "pieceSelection"
return(results)
}
res <- cutSeqOpt(data = data, l = 0.5, nChoose = 1,
params = list(c(0, -1, 1, 0), c(0, -1, 1, 0)))
res
# ----- all tests together: -----
allTests <- matrix(c(class(try(testNaiveNormalData())) != "try-error",
class(try(testOneOptNormalData())) != "try-error",
class(try(testSeqOptNormalData())) != "try-error",
class(try(testSplitSearchNormalData())) != "try-error",
class(try(testCombSearchNormalData())) != "try-error",
class(try(testNaiveAllSelected())) != "try-error",
NA,
NA,
class(try(testSplitSearchAllSelected())) != "try-error",
class(try(testCombSearchAllSelected())) != "try-error",
NA,
class(try(testOneOptMaxQuality())) != "try-error",
class(try(testSeqOptMaxQuality())) != "try-error",
class(try(testSplitSearchMaxQuality())) != "try-error",
class(try(testCombSearchMaxQuality())) != "try-error",
class(try(testNaiveStartBiggerThanZero())) != "try-error",
class(try(testOneOptStartBiggerThanZero())) != "try-error",
class(try(testSeqOptStartBiggerThanZero())) != "try-error",
class(try(testSplitSearchStartBiggerThanZero())) != "try-error",
class(try(testCombSearchStartBiggerThanZero())) != "try-error",
class(try(testNaiveStartSmallerThanZero())) != "try-error",
class(try(testOneOptStartSmallerThanZero())) != "try-error",
class(try(testSeqOptStartSmallerThanZero())) != "try-error",
class(try(testSplitSearchStartSmallerThanZero())) != "try-error",
class(try(testCombSearchStartSmallerThanZero())) != "try-error",
class(try(testNaiveNonMatchingPositions())) != "try-error",
class(try(testOneOptNonMatchingPositions())) != "try-error",
class(try(testSeqOptNonMatchingPositions())) != "try-error",
class(try(testSplitSearchNonMatchingPositions())) != "try-error",
class(try(testCombSearchNonMatchingPositions())) != "try-error"),
ncol = 5, byrow = TRUE)
colnames(allTests) <- c("Naive", "OneOpt", "SeqOpt", "SplitSearch", "CombSearch")
rownames(allTests) <- c("NormalData", "AllSelected", "MaxQuality", "StartBiggerThanZero",
"StartSmallerThanZero", "NonMatchingPositions")
allTests
# object of class pieceSelection including:
#  summary - numeric with a summary of the found pieces, including length, number,
#            sum of length, length of given material, waste of material, relative
#            amount of waste
#  piecePos - matrix with two columns. Each row corresponds to one found piece.
#             First column gives its start position, second column its end position.
#  pieceOutliers - matrix, relative amount of outliers per piece (row) and
#                  parameter (column)
#  data - the input argument data
#  params - the input argument params
cutSplitSearch <- function(data, params, length){
cat("Finding maximum number of pieces...\n")
flush.console()
resNaive <- cutNaive(data, params, length)
nPieces <- resNaive[["summary"]][2]
if(nPieces == 0){
return(resNaive)
}
# Try to partition the problem (see paper) to reduce CPU and RAM load
# .Machine$double.eps^0.5 due to numeric inaccuracies of float numbers
beforeSkip <- which(abs(resNaive$`piecePositions`[-1 , 1] - resNaive$`piecePositions`[-nPieces, 2]) > .Machine$double.eps^0.5)
nPiecePart <- diff(c(0, beforeSkip, nPieces))
partitions <- c(min(data[[1]][, 2]), rep(resNaive$`piecePositions`[beforeSkip + 1, 1], each = 2), max(data[[1]][, 2]))
partitions <- matrix(partitions, ncol = 2, byrow = TRUE)
# partitions is now a matrix that includes start and end positions of the
# search area for the subproblems
nPartitions <- dim(partitions)[1]
if(nPartitions){
cat("Partitioning problem into", nPartitions, "subproblems.\n")
flush.console()
}
# For each partition, search for pieces
resPart <- list()
for(p in seq(nPartitions)){
if(nPartitions > 1){
cat("Solving", p, "/", nPartitions, ": ")
flush.console()
}
# create a fitting sub-dataset for each partition:
dataPart <- data
partStart <- min(which(dataPart[[1]][, 2] >= partitions[p, 1]))
partEnd <- max(which(dataPart[[1]][, 2] <= partitions[p, 2]))
dataPart[[1]] <- dataPart[[1]][partStart:partEnd, ]
# Add points at start and end of partition to actually search the whole
# partition area
addFirst <- c(data[[1]][max(partStart - 1, 1), 1], partitions[p, 1])
if(partStart > 1){
# Add mid point between first point and point before
midFirst <- c(data[[1]][partStart, 1],
mean(data[[1]][c(partStart - 1, partStart), 2]))
if(midFirst[2] > addFirst[2])
addFirst <- rbind(addFirst, midFirst)
}
addLast <- c(data[[1]][partEnd, 1], partitions[p, 2])
dataPart[[1]] <- rbind(addFirst, dataPart[[1]], addLast)
# apply cutCombSearch
resPart[[p]] <- cutCombSearch(dataPart, params, length, nPiecePart[p])
}
# Construct output
results <- list()
results[["summary"]] <- c("length" = length,
"nPieces" = sum(sapply(resPart, function(x) x$summary[2])),
"goodMaterial" = sum(sapply(resPart, function(x) x$summary[3])),
"allMaterial" = unname(resNaive$summary[4]),
"badMaterial" = unname(resNaive$summary[4] - sum(sapply(resPart, function(x) x$summary[3]))),
"badMaterialPercent" = 0)
results[["summary"]][6] <- results[["summary"]][5] / results[["summary"]][4] * 100
results[["piecePositions"]] <- do.call(rbind, lapply(resPart, function(x) x$'piecePositions'))
results[["pieceOutliers"]] <-	do.call(rbind, lapply(resPart, function(x) x$'pieceOutliers'))
results[["data"]] <- data
results[["params"]] <- params
class(results) <- "pieceSelection"
return(results)
}
# ----- all tests together: -----
allTests <- matrix(c(class(try(testNaiveNormalData())) != "try-error",
class(try(testOneOptNormalData())) != "try-error",
class(try(testSeqOptNormalData())) != "try-error",
class(try(testSplitSearchNormalData())) != "try-error",
class(try(testCombSearchNormalData())) != "try-error",
class(try(testNaiveAllSelected())) != "try-error",
NA,
NA,
class(try(testSplitSearchAllSelected())) != "try-error",
class(try(testCombSearchAllSelected())) != "try-error",
NA,
class(try(testOneOptMaxQuality())) != "try-error",
class(try(testSeqOptMaxQuality())) != "try-error",
class(try(testSplitSearchMaxQuality())) != "try-error",
class(try(testCombSearchMaxQuality())) != "try-error",
class(try(testNaiveStartBiggerThanZero())) != "try-error",
class(try(testOneOptStartBiggerThanZero())) != "try-error",
class(try(testSeqOptStartBiggerThanZero())) != "try-error",
class(try(testSplitSearchStartBiggerThanZero())) != "try-error",
class(try(testCombSearchStartBiggerThanZero())) != "try-error",
class(try(testNaiveStartSmallerThanZero())) != "try-error",
class(try(testOneOptStartSmallerThanZero())) != "try-error",
class(try(testSeqOptStartSmallerThanZero())) != "try-error",
class(try(testSplitSearchStartSmallerThanZero())) != "try-error",
class(try(testCombSearchStartSmallerThanZero())) != "try-error",
class(try(testNaiveNonMatchingPositions())) != "try-error",
class(try(testOneOptNonMatchingPositions())) != "try-error",
class(try(testSeqOptNonMatchingPositions())) != "try-error",
class(try(testSplitSearchNonMatchingPositions())) != "try-error",
class(try(testCombSearchNonMatchingPositions())) != "try-error"),
ncol = 5, byrow = TRUE)
colnames(allTests) <- c("Naive", "OneOpt", "SeqOpt", "SplitSearch", "CombSearch")
rownames(allTests) <- c("NormalData", "AllSelected", "MaxQuality", "StartBiggerThanZero",
"StartSmallerThanZero", "NonMatchingPositions")
allTests
testSplitSearchNormalData <- function(){
res <- cutSplitSearch(data = simData, l = 0.5,
params = list(c(9.2, 9.11, 9.48, 0.05), c(117, 115, 119, 0.05)))
expect_true(arePiecePositionsOk(res))
expect_equal(as.numeric(res$summary["nPieces"]), 4)
}
testSplitSearchNormalData()
testSplitSearchNormalData()
clabs
nmi
# object of class pieceSelection including:
#  summary - numeric with a summary of the found pieces, including length, number,
#            sum of length, length of given material, waste of material, relative
#            amount of waste
#  piecePos - matrix with two columns. Each row corresponds to one found piece.
#             First column gives its start position, second column its end position.
#  pieceOutliers - matrix, relative amount of outliers per piece (row) and
#                  parameter (column)
#  data - the input argument data
#  params - the input argument params
cutSplitSearch <- function(data, params, length){
cat("Finding maximum number of pieces...\n")
flush.console()
resNaive <- cutNaive(data, params, length)
nPieces <- resNaive[["summary"]][2]
if(nPieces == 0){
return(resNaive)
}
# Try to partition the problem (see paper) to reduce CPU and RAM load
# .Machine$double.eps^0.5 due to numeric inaccuracies of float numbers
beforeSkip <- which(abs(resNaive$`piecePositions`[-1 , 1] - resNaive$`piecePositions`[-nPieces, 2]) > .Machine$double.eps^0.5)
nPiecePart <- diff(c(0, beforeSkip, nPieces))
partitions <- c(min(data[[1]][, 2]), rep(resNaive$`piecePositions`[beforeSkip + 1, 1], each = 2), max(data[[1]][, 2]))
partitions <- matrix(partitions, ncol = 2, byrow = TRUE)
# partitions is now a matrix that includes start and end positions of the
# search area for the subproblems
nPartitions <- dim(partitions)[1]
if(nPartitions){
cat("Partitioning problem into", nPartitions, "subproblems.\n")
flush.console()
}
browser()
# For each partition, search for pieces
resPart <- list()
for(p in seq(nPartitions)){
if(nPartitions > 1){
cat("Solving", p, "/", nPartitions, ": ")
flush.console()
}
# create a fitting sub-dataset for each partition:
dataPart <- data
partStart <- min(which(dataPart[[1]][, 2] >= partitions[p, 1]))
partEnd <- max(which(dataPart[[1]][, 2] <= partitions[p, 2]))
dataPart[[1]] <- dataPart[[1]][partStart:partEnd, ]
# Add points at start and end of partition to actually search the whole
# partition area
addFirst <- c(data[[1]][max(partStart - 1, 1), 1], partitions[p, 1])
if(partStart > 1){
# Add mid point between first point and point before
midFirst <- c(data[[1]][partStart, 1],
mean(data[[1]][c(partStart - 1, partStart), 2]))
if(midFirst[2] > addFirst[2])
addFirst <- rbind(addFirst, midFirst)
}
addLast <- c(data[[1]][partEnd, 1], partitions[p, 2])
dataPart[[1]] <- rbind(addFirst, dataPart[[1]], addLast)
# apply cutCombSearch
resPart[[p]] <- cutCombSearch(dataPart, params, length, nPiecePart[p])
}
# Construct output
results <- list()
results[["summary"]] <- c("length" = length,
"nPieces" = sum(sapply(resPart, function(x) x$summary[2])),
"goodMaterial" = sum(sapply(resPart, function(x) x$summary[3])),
"allMaterial" = unname(resNaive$summary[4]),
"badMaterial" = unname(resNaive$summary[4] - sum(sapply(resPart, function(x) x$summary[3]))),
"badMaterialPercent" = 0)
results[["summary"]][6] <- results[["summary"]][5] / results[["summary"]][4] * 100
results[["piecePositions"]] <- do.call(rbind, lapply(resPart, function(x) x$'piecePositions'))
results[["pieceOutliers"]] <-	do.call(rbind, lapply(resPart, function(x) x$'pieceOutliers'))
results[["data"]] <- data
results[["params"]] <- params
class(results) <- "pieceSelection"
return(results)
}
testSplitSearchNormalData()
partStart
partEnd
addFirst
midFirst
addFirst
addFirst
midFirst
rbind(addFirst, midFirst)
dataPart[[1]] <- rbind(addFirst, dataPart[[1]], addLast)
addFirst
addLast
str(dataPart[[1]])
dataPart[[1]][, 1:2] <- rbind(addFirst, dataPart[[1]], addLast)
rbind(addFirst, dataPart[[1]])
rbind(dataPart[[1]], addLast)
?rbind
rbind(addFirst, unname(dataPart[[1]]), addLast)
names(addFirst) <- names(dataPart[[1]])
addFirst
dataPart[[1]] <- rbind(addFirst, dataPart[[1]], addLast)
Q
testSplitSearchNormalData()
addFirst
addLast
addFirst
addLast
addFirst
str(addFirst)
rownames(addFirst) <- NULL
dataPart[[1]] <- rbind(addFirst, dataPart[[1]], addLast)
colnames(addFirst) <- colnames(dataPart[[1]])
dataPart[[1]] <- rbind(addFirst, dataPart[[1]], addLast)
# object of class pieceSelection including:
#  summary - numeric with a summary of the found pieces, including length, number,
#            sum of length, length of given material, waste of material, relative
#            amount of waste
#  piecePos - matrix with two columns. Each row corresponds to one found piece.
#             First column gives its start position, second column its end position.
#  pieceOutliers - matrix, relative amount of outliers per piece (row) and
#                  parameter (column)
#  data - the input argument data
#  params - the input argument params
cutSplitSearch <- function(data, params, length){
cat("Finding maximum number of pieces...\n")
flush.console()
resNaive <- cutNaive(data, params, length)
nPieces <- resNaive[["summary"]][2]
if(nPieces == 0){
return(resNaive)
}
# Try to partition the problem (see paper) to reduce CPU and RAM load
# .Machine$double.eps^0.5 due to numeric inaccuracies of float numbers
beforeSkip <- which(abs(resNaive$`piecePositions`[-1 , 1] - resNaive$`piecePositions`[-nPieces, 2]) > .Machine$double.eps^0.5)
nPiecePart <- diff(c(0, beforeSkip, nPieces))
partitions <- c(min(data[[1]][, 2]), rep(resNaive$`piecePositions`[beforeSkip + 1, 1], each = 2), max(data[[1]][, 2]))
partitions <- matrix(partitions, ncol = 2, byrow = TRUE)
# partitions is now a matrix that includes start and end positions of the
# search area for the subproblems
nPartitions <- dim(partitions)[1]
if(nPartitions){
cat("Partitioning problem into", nPartitions, "subproblems.\n")
flush.console()
}
# For each partition, search for pieces
resPart <- list()
for(p in seq(nPartitions)){
if(nPartitions > 1){
cat("Solving", p, "/", nPartitions, ": ")
flush.console()
}
# create a fitting sub-dataset for each partition:
dataPart <- data
partStart <- min(which(dataPart[[1]][, 2] >= partitions[p, 1]))
partEnd <- max(which(dataPart[[1]][, 2] <= partitions[p, 2]))
dataPart[[1]] <- dataPart[[1]][partStart:partEnd, ]
# Add points at start and end of partition to actually search the whole
# partition area
addFirst <- c(data[[1]][max(partStart - 1, 1), 1], partitions[p, 1])
if(partStart > 1){
# Add mid point between first point and point before
midFirst <- c(data[[1]][partStart, 1],
mean(data[[1]][c(partStart - 1, partStart), 2]))
if(midFirst[2] > addFirst[2])
addFirst <- rbind(addFirst, midFirst)
colnames(addFirst) <- colnames(dataPart[[1]]) # avoid problems with rbind
}
addLast <- c(data[[1]][partEnd, 1], partitions[p, 2])
# Avoid conflicts with rbind
dataPart[[1]] <- rbind(addFirst, dataPart[[1]], addLast)
# apply cutCombSearch
resPart[[p]] <- cutCombSearch(dataPart, params, length, nPiecePart[p])
}
# Construct output
results <- list()
results[["summary"]] <- c("length" = length,
"nPieces" = sum(sapply(resPart, function(x) x$summary[2])),
"goodMaterial" = sum(sapply(resPart, function(x) x$summary[3])),
"allMaterial" = unname(resNaive$summary[4]),
"badMaterial" = unname(resNaive$summary[4] - sum(sapply(resPart, function(x) x$summary[3]))),
"badMaterialPercent" = 0)
results[["summary"]][6] <- results[["summary"]][5] / results[["summary"]][4] * 100
results[["piecePositions"]] <- do.call(rbind, lapply(resPart, function(x) x$'piecePositions'))
results[["pieceOutliers"]] <-	do.call(rbind, lapply(resPart, function(x) x$'pieceOutliers'))
results[["data"]] <- data
results[["params"]] <- params
class(results) <- "pieceSelection"
return(results)
}
allTests <- matrix(c(class(try(testNaiveNormalData())) != "try-error",
class(try(testOneOptNormalData())) != "try-error",
class(try(testSeqOptNormalData())) != "try-error",
class(try(testSplitSearchNormalData())) != "try-error",
class(try(testCombSearchNormalData())) != "try-error",
class(try(testNaiveAllSelected())) != "try-error",
NA,
NA,
class(try(testSplitSearchAllSelected())) != "try-error",
class(try(testCombSearchAllSelected())) != "try-error",
NA,
class(try(testOneOptMaxQuality())) != "try-error",
class(try(testSeqOptMaxQuality())) != "try-error",
class(try(testSplitSearchMaxQuality())) != "try-error",
class(try(testCombSearchMaxQuality())) != "try-error",
class(try(testNaiveStartBiggerThanZero())) != "try-error",
class(try(testOneOptStartBiggerThanZero())) != "try-error",
class(try(testSeqOptStartBiggerThanZero())) != "try-error",
class(try(testSplitSearchStartBiggerThanZero())) != "try-error",
class(try(testCombSearchStartBiggerThanZero())) != "try-error",
class(try(testNaiveStartSmallerThanZero())) != "try-error",
class(try(testOneOptStartSmallerThanZero())) != "try-error",
class(try(testSeqOptStartSmallerThanZero())) != "try-error",
class(try(testSplitSearchStartSmallerThanZero())) != "try-error",
class(try(testCombSearchStartSmallerThanZero())) != "try-error",
class(try(testNaiveNonMatchingPositions())) != "try-error",
class(try(testOneOptNonMatchingPositions())) != "try-error",
class(try(testSeqOptNonMatchingPositions())) != "try-error",
class(try(testSplitSearchNonMatchingPositions())) != "try-error",
class(try(testCombSearchNonMatchingPositions())) != "try-error"),
ncol = 5, byrow = TRUE)
colnames(allTests) <- c("Naive", "OneOpt", "SeqOpt", "SplitSearch", "CombSearch")
rownames(allTests) <- c("NormalData", "AllSelected", "MaxQuality", "StartBiggerThanZero",
"StartSmallerThanZero", "NonMatchingPositions")
allTests
# object of class pieceSelection including:
#  summary - numeric with a summary of the found pieces, including length, number,
#            sum of length, length of given material, waste of material, relative
#            amount of waste
#  piecePos - matrix with two columns. Each row corresponds to one found piece.
#             First column gives its start position, second column its end position.
#  pieceOutliers - matrix, relative amount of outliers per piece (row) and
#                  parameter (column)
#  data - the input argument data
#  params - the input argument params
cutSplitSearch <- function(data, params, length){
cat("Finding maximum number of pieces...\n")
flush.console()
resNaive <- cutNaive(data, params, length)
nPieces <- resNaive[["summary"]][2]
if(nPieces == 0){
return(resNaive)
}
# Try to partition the problem (see paper) to reduce CPU and RAM load
# .Machine$double.eps^0.5 due to numeric inaccuracies of float numbers
beforeSkip <- which(abs(resNaive$`piecePositions`[-1 , 1] - resNaive$`piecePositions`[-nPieces, 2]) > .Machine$double.eps^0.5)
nPiecePart <- diff(c(0, beforeSkip, nPieces))
partitions <- c(min(data[[1]][, 2]), rep(resNaive$`piecePositions`[beforeSkip + 1, 1], each = 2), max(data[[1]][, 2]))
partitions <- matrix(partitions, ncol = 2, byrow = TRUE)
# partitions is now a matrix that includes start and end positions of the
# search area for the subproblems
nPartitions <- dim(partitions)[1]
if(nPartitions){
cat("Partitioning problem into", nPartitions, "subproblems.\n")
flush.console()
}
# For each partition, search for pieces
resPart <- list()
for(p in seq(nPartitions)){
if(nPartitions > 1){
cat("Solving", p, "/", nPartitions, ": ")
flush.console()
}
# create a fitting sub-dataset for each partition:
dataPart <- data
partStart <- min(which(dataPart[[1]][, 2] >= partitions[p, 1]))
partEnd <- max(which(dataPart[[1]][, 2] <= partitions[p, 2]))
dataPart[[1]] <- dataPart[[1]][partStart:partEnd, ]
# Add points at start and end of partition to actually search the whole
# partition area
addFirst <- c(data[[1]][max(partStart - 1, 1), 1], partitions[p, 1])
if(partStart > 1){
# Add mid point between first point and point before
midFirst <- c(data[[1]][partStart, 1],
mean(data[[1]][c(partStart - 1, partStart), 2]))
if(midFirst[2] > addFirst[2]){
addFirst <- rbind(addFirst, midFirst)
colnames(addFirst) <- colnames(dataPart[[1]]) # avoid problems with rbind
}
}
addLast <- c(data[[1]][partEnd, 1], partitions[p, 2])
# Avoid conflicts with rbind
dataPart[[1]] <- rbind(addFirst, dataPart[[1]], addLast)
# apply cutCombSearch
resPart[[p]] <- cutCombSearch(dataPart, params, length, nPiecePart[p])
}
# Construct output
results <- list()
results[["summary"]] <- c("length" = length,
"nPieces" = sum(sapply(resPart, function(x) x$summary[2])),
"goodMaterial" = sum(sapply(resPart, function(x) x$summary[3])),
"allMaterial" = unname(resNaive$summary[4]),
"badMaterial" = unname(resNaive$summary[4] - sum(sapply(resPart, function(x) x$summary[3]))),
"badMaterialPercent" = 0)
results[["summary"]][6] <- results[["summary"]][5] / results[["summary"]][4] * 100
results[["piecePositions"]] <- do.call(rbind, lapply(resPart, function(x) x$'piecePositions'))
results[["pieceOutliers"]] <-	do.call(rbind, lapply(resPart, function(x) x$'pieceOutliers'))
results[["data"]] <- data
results[["params"]] <- params
class(results) <- "pieceSelection"
return(results)
}
allTests <- matrix(c(class(try(testNaiveNormalData())) != "try-error",
class(try(testOneOptNormalData())) != "try-error",
class(try(testSeqOptNormalData())) != "try-error",
class(try(testSplitSearchNormalData())) != "try-error",
class(try(testCombSearchNormalData())) != "try-error",
class(try(testNaiveAllSelected())) != "try-error",
NA,
NA,
class(try(testSplitSearchAllSelected())) != "try-error",
class(try(testCombSearchAllSelected())) != "try-error",
NA,
class(try(testOneOptMaxQuality())) != "try-error",
class(try(testSeqOptMaxQuality())) != "try-error",
class(try(testSplitSearchMaxQuality())) != "try-error",
class(try(testCombSearchMaxQuality())) != "try-error",
class(try(testNaiveStartBiggerThanZero())) != "try-error",
class(try(testOneOptStartBiggerThanZero())) != "try-error",
class(try(testSeqOptStartBiggerThanZero())) != "try-error",
class(try(testSplitSearchStartBiggerThanZero())) != "try-error",
class(try(testCombSearchStartBiggerThanZero())) != "try-error",
class(try(testNaiveStartSmallerThanZero())) != "try-error",
class(try(testOneOptStartSmallerThanZero())) != "try-error",
class(try(testSeqOptStartSmallerThanZero())) != "try-error",
class(try(testSplitSearchStartSmallerThanZero())) != "try-error",
class(try(testCombSearchStartSmallerThanZero())) != "try-error",
class(try(testNaiveNonMatchingPositions())) != "try-error",
class(try(testOneOptNonMatchingPositions())) != "try-error",
class(try(testSeqOptNonMatchingPositions())) != "try-error",
class(try(testSplitSearchNonMatchingPositions())) != "try-error",
class(try(testCombSearchNonMatchingPositions())) != "try-error"),
ncol = 5, byrow = TRUE)
colnames(allTests) <- c("Naive", "OneOpt", "SeqOpt", "SplitSearch", "CombSearch")
rownames(allTests) <- c("NormalData", "AllSelected", "MaxQuality", "StartBiggerThanZero",
"StartSmallerThanZero", "NonMatchingPositions")
allTests
?install.packages
